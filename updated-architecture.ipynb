{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries and set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langchain_core.tools import tool\n",
    "import functools\n",
    "from langchain_core.messages import AIMessage\n",
    "import operator\n",
    "from typing import Sequence , List\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"tutor agents\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "GPT_MODEL = \"gpt-4o\"\n",
    "client = OpenAI()\n",
    "llm = ChatOpenAI(model=GPT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create necessary function for agent creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a node for a given agent\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_agent_prompt(agentName: str, tools) -> str:\n",
    "    ''' function to determine custom prompt based on the agent type (only 3 atm)\n",
    "    need to add tools available to prompts\n",
    "    '''\n",
    "    try:\n",
    "        if agentName == 'tracker':\n",
    "            return (\n",
    "                \"system\",\n",
    "                \"You are the tracker,\"\n",
    "                \"Your role is to supervise the role of the tutoring agents.\"\n",
    "                \"Please state your role clearly\" #! debugging line to change later\n",
    "                f\"your tools are {[tool.name for tool in tools]}\"\n",
    "            )\n",
    "        elif agentName == 'orchestor':\n",
    "            return (\n",
    "                \"system\",\n",
    "                \"your are the orchestor\"\n",
    "                \"your role is to:\"\n",
    "                \"1: retrieve the contents of a topic from the vector store,\"\n",
    "                \"2. seperate the contents into chunks that have coherent content and goal in a dictionary\" #? to modify later, not clear enough\n",
    "                \"where the keys are the agent names and the values are the content.\"\n",
    "                \"3. generate a sequence of tutoring agents to call in a list.\"\n",
    "                \"Please state your role clearly\"\n",
    "                f\"your tools are {[tool.name for tool in tools]}\"\n",
    "                \"\"\n",
    "            )\n",
    "        elif agentName == 'communicator':\n",
    "            return (\n",
    "                \"system\",\n",
    "                \"you are the communicator\"\n",
    "                \"you communicate in a friendly way with the user\"\n",
    "                \"your role is to give user recommendations about learning\"\n",
    "                \"based on the user's profile and the user progress\" #there will be a function to access this\n",
    "                \"Please state your role clearly\"\n",
    "                f\"your tools are {[tool.name for tool in tools]}\"\n",
    "            )\n",
    "    except:\n",
    "        raise 'agentName is incorrect'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' FUNCTION TO CREATE THEE FOLLOWING AGENTS: TRACKER, COMMUNICATOR, ORCHESTRATOR'''\n",
    "''' the system_message var is used for the general personality of the agent, determined during its creation '''\n",
    "\n",
    "def create_agent(agentName: str, llm, tools, system_message: str): #* for tracker, communicator and orchestor\n",
    "    \"\"\"Create main agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            set_agent_prompt(agentName=agentName, tools=tools),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    return prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' prompt list '''\n",
    "#! very important list\n",
    "global_prompts_list = ['moien'] #accessible by anyone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIX FOR GETTING CONTENT\n",
    "\n",
    "PERSONALITY OF TUTOR AGENT IS FIXED\n",
    "IT USES A TOOL TO GET THE CONTENT STORED IN A LIST CREATED BY THE ORCHESTE (and then removes it so next agent can straight up take the next content)\n",
    "THAT WAY NO CHANGE OF PROMPT IS NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tutor_agent(agentName: str, llm, system_message: str): #* for tracker, communicator and orchestor\n",
    "    \"\"\"Create main agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            \"system\",\n",
    "            global_prompts_list[0],\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    global_prompts_list.pop(0)\n",
    "\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    return prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' tool function for all tutor agents to retrieve their prompts \n",
    "this function will probably need some tuning and tests to ensure there are no problems coming from the orchester\n",
    "'''\n",
    "#! NOT USED KEEPING JUST IN CASE\n",
    "@tool \n",
    "def getTutorPrompt() -> str:\n",
    "    ''' return the first element of the global prompts list '''\n",
    "    prompt = global_prompts_list[0][1] # -> (Agent, 'Personality+Content') -> retrive personality and content\n",
    "    assert type(prompt) == str, 'prompt is not a string...'\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create orchester node (not yet!) and it's tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def generateTutorPrompt(promptDict: dict) -> None: #none since we update the global list but dont return it\n",
    "    ''' write in a global list all the different contents and prompts\n",
    "    ex: structure -> [(agent, personality+content)]\n",
    "    global contents_list = \n",
    "    [(conversational_agent,'you are the conversation agent, you must teach the lesson with the following content: -moien, -addi'),\n",
    "    (listening_agent, 'you are the listening agent, you must...content: -audio of the colors) etc...]\n",
    "    '''\n",
    "    print('Updating the global list (in theory)')\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tracker agent node and it's tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TOOLS FOR THE TRACKER '''\n",
    "@tool\n",
    "def start_signal(agentName: str) -> str:\n",
    "    ''' function to determine what agent need to be woken up\n",
    "    ex: agentName <-> the ID present in the shared list between orchestrator and tracker\n",
    "    output -> \"conversational_agent\" <-> used by the router to know where to go in the graph\n",
    "    '''\n",
    "    return agentName\n",
    "\n",
    "@tool\n",
    "def create_progress_report(rapport: str) -> None: \n",
    "    ''' write all the reports in file 'address' '''\n",
    "    print('Tool not writing anything yet but called properly!') #debugging tool to see something happenend\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_agent = create_agent(\n",
    "    agentName='tracker', \n",
    "    llm=llm, \n",
    "    tools=[start_signal, create_progress_report], \n",
    "    system_message=\"You are the tracker agent, you job is to track agent tutors and to create reports for user progress\" #* to be redefined later\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_node = functools.partial(agent_node, agent=tracker_agent, name='tracker_node')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Conversational agent node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_agent = create_tutor_agent(\n",
    "    agentName='conversational',\n",
    "    llm=llm,\n",
    "    system_message=\"You are the conversational agent, your job is to teach the lesson to the student through conversation\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
